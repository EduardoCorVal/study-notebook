
- prevent the denial-of-service traffic from entering your Virtual Private Cloud (VPC) network:
    -> deploy an external HTTP(S) load balancer, configure Google Cloud Armor, and move the application onto Compute Engine virtual machines.

- Each Pod represents a single instance of a microservice. By deploying each microservice as a Deployment, the cloud architect can ensure that each microservice is replicated to the desired number of instances. 

- **Use containers and the Kubernetes Engine. This migration strategy is called Improve and Move**
- **Not to make unnecessary changes before moving this application to the cloud. This migration strategy is called Lift and Shift.**

- web front end and REST API backend on separate App Engine services, and the database on Cloud Spanner

- A warm standby approach with minimal running infrastructure in another region and replicate data to a multi-regional Cloud Storage bucket.

- **Anthos to centrally manage and monitor all GKE clusters.**

**Google Cloud Dedicated Interconnect:** Enables data replication between on-premises data centers and GCP projects. Provides a direct physical connection between your on-premises network and Google's network

**Partner Interconnect connection:** allows the customer to lower latency by connecting directly to a partner network that is directly connected to Google

**minimize data loss in the event of a significant failure**:
    - Binary logging
    - Automated backups

- revert to the previous version:
    - set the previous version as default to route all traffic in App Engine Console.

- Shielded VMs that only runs digitally verified boot components.

**App Engine Flexible**: managed platform allows to build and run containerized applications. automatic scaling, load balancing, and monitoring.

**Use preemptible VMs for encoding and transcoding tasks**

- prevent data loss when more data arrives than the virtual machines can process:
    - write data to the Cloud Pub/Sub queue, and the application should read data from the queue.
